
# MACHINE LEARNING II ‚Äî ACTIVIDAD II  
## Predicci√≥n de Churn en Clientes  
### **Autores: Marcelo Carmona ‚Äî Paula √Ålvarez**

---

## üìå Descripci√≥n del Proyecto

Este repositorio contiene el desarrollo completo de la **Actividad II** del curso **Machine Learning II**, cuyo objetivo es aplicar t√©cnicas de modelamiento supervisado para la **predicci√≥n de churn** en un dataset real de clientes.

A lo largo del proyecto se realizan:

- Preprocesamiento y limpieza del dataset  
- Entrenamiento de modelos base  
- Optimizaci√≥n de modelos mediante **Random Search**  
- An√°lisis de varianza y estabilidad del Random Forest  
- Uso de **pesos por clase** para tratar el desbalance  
- Comparaci√≥n entre modelos  
- Evaluaci√≥n con m√©tricas de clasificaci√≥n y curvas ROC / PR  
- Conclusiones t√©cnicas y de negocio  

---

## üéØ Objetivos del An√°lisis

1. Preparar adecuadamente un dataset de churn (variables categ√≥ricas + num√©ricas).  
2. Entrenar modelos base: √Årbol de decisi√≥n y Random Forest.  
3. Optimizar Random Forest mediante **RandomizedSearchCV**.  
4. Estudiar la reducci√≥n de varianza variando el n√∫mero de √°rboles.  
5. Evaluar m√©tricas clave:
   - Accuracy
   - Precision
   - Recall
   - F1-score
   - ROC-AUC
   - PR-AUC
6. Analizar diferencias entre modelos lineales, √°rboles y ensambles.  
7. Realizar un an√°lisis cr√≠tico de desempe√±o y aplicabilidad.  

---

## üîß Tecnolog√≠as Utilizadas

- **Python 3.10+**  
- **scikit-learn**  
- **pandas, numpy**  
- **matplotlib, seaborn**  
- **Jupyter Notebook**  

---

## üìä Resultados Principales

### üîπ Comparaci√≥n entre modelos con `class_weight="balanced"`

| Modelo                      | Accuracy | Precision | Recall | F1   | ROC-AUC | PR-AUC |
|----------------------------|----------|-----------|--------|------|---------|--------|
| √Årbol de decisi√≥n          | 0.7138   | 0.4603    | 0.4492 | 0.4547 | 0.6300 | 0.3548 |
| Random Forest Optimizado   | **0.7692** | **0.5556** | **0.6551** | **0.6012** | **0.8358** | **0.6423** |

---

## üß† Conclusiones Principales

- El **Random Forest optimizado** supera ampliamente al √Årbol de decisi√≥n.  
- La varianza disminuye significativamente al aumentar los √°rboles, validando la teor√≠a del bagging.  
- En churn, la m√©trica m√°s relevante es **PR-AUC**, debido al desbalance de clases.  
- Para estrategias de retenci√≥n, el modelo con mayor Recall y PR-AUC (Random Forest) es el m√°s adecuado.  
- El √°rbol individual es √∫til para interpretaci√≥n, pero su desempe√±o es insuficiente.  

---


``
