# Actividad III ‚Äì *Machine Learning II*
Autores: Marcelo Carmona - Paula Alvarez

## üìå Descripci√≥n General
Este proyecto corresponde a la **Actividad 3 del curso Machine Learning II**, realizada por *Paula √Ålvarez y Marcelo Carmona*.  
El objetivo es aplicar distintos modelos de clasificaci√≥n al problema de **churn prediction** (abandono de clientes), evaluando su desempe√±o y discutiendo ventajas, limitaciones e interpretabilidad.

Se implementan dos enfoques principales:
- **Na√Øve Bayes** (GaussianNB y BernoulliNB).
- **Support Vector Machines (SVM)** con kernel lineal y RBF.

Adem√°s, se incluyen diagn√≥sticos de dependencia entre predictores (correlaciones, Cram√©r‚Äôs V, VIF) para analizar el impacto en los supuestos de los modelos.

---

## üõ†Ô∏è Librer√≠as Utilizadas
- **Manipulaci√≥n y visualizaci√≥n:** `numpy`, `pandas`, `matplotlib`, `seaborn`
- **Modelado:** `scikit-learn` (pipelines, preprocesamiento, Na√Øve Bayes, SVM, m√©tricas)
- **Estad√≠stica:** `scipy.stats.contingency` (Cram√©r‚Äôs V)
- **Infraestructura:** `google.colab` para montaje de Google Drive

---

## üîÑ Flujo del C√≥digo
1. **Carga de datos:**  
   - Dataset `data-churn.csv` desde Google Drive.  
   - Exploraci√≥n inicial: distribuci√≥n de la variable objetivo, estad√≠sticas b√°sicas.

2. **Preprocesamiento:**  
   - Imputaci√≥n de valores faltantes (mediana/moda).  
   - Escalado de num√©ricas con `StandardScaler`.  
   - Codificaci√≥n categ√≥rica con `OneHotEncoder`.  
   - Conversi√≥n de variable objetivo a formato binario.

3. **Modelos Na√Øve Bayes:**  
   - **GaussianNB:** sobre matriz densa (num√©ricas escaladas + one-hot).  
   - **BernoulliNB:** discretizaci√≥n de num√©ricas en 2 bins + one-hot.  
   - **GridSearchCV** para optimizaci√≥n de hiperpar√°metros.  
   - Evaluaci√≥n con m√©tricas: Accuracy, F1 macro, ROC-AUC, PR-AUC.

4. **Diagn√≥stico de Dependencia:**  
   - Correlaciones Pearson/Spearman globales y por clase.  
   - Asociaci√≥n categ√≥rica con **Cram√©r‚Äôs V**.  
   - Multicolinealidad num√©rica con **VIF**.  
   - Discusi√≥n sobre impacto en supuestos de independencia de Na√Øve Bayes.

5. **Modelos SVM:**  
   - **Lineal (LinearSVC)**: interpretabilidad v√≠a pesos.  
   - **RBF (SVC kernel=rbf)**: captura no linealidad.  
   - **RandomizedSearchCV** para hiperpar√°metros `C` y `gamma`.  
   - Calibraci√≥n de probabilidades con `CalibratedClassifierCV`.  
   - Evaluaci√≥n en test con m√©tricas y curvas ROC/PR.

6. **An√°lisis Cr√≠tico:**  
   - Comparaci√≥n entre NB y SVM.  
   - Discusi√≥n sobre interpretabilidad, escalamiento, dimensionalidad y calibraci√≥n de probabilidades.

---

## üìä Resultados Obtenidos

### Na√Øve Bayes
- **GaussianNB** y **BernoulliNB** fueron entrenados.  
- Selecci√≥n final basada en **F1 macro**.  
- M√©tricas en test (ejemplo representativo):
  - Accuracy ‚âà 0.80  
  - F1 macro ‚âà 0.78  
  - ROC-AUC macro ‚âà 0.82  
  - PR-AUC macro ‚âà 0.75  
- Se observ√≥ que la **dependencia entre predictores** afecta la calibraci√≥n de probabilidades.

### SVM
- **Lineal (calibrado):**
  - Accuracy ‚âà 0.82  
  - F1 macro ‚âà 0.80  
  - ROC-AUC macro ‚âà 0.84  
  - PR-AUC macro ‚âà 0.77  
- **RBF (calibrado):**
  - Accuracy ‚âà 0.85  
  - F1 macro ‚âà 0.83  
  - ROC-AUC macro ‚âà 0.87  
  - PR-AUC macro ‚âà 0.80  
- El kernel RBF super√≥ al lineal en todas las m√©tricas, aunque con menor interpretabilidad.

### Comparaci√≥n NB vs SVM
| Modelo        | Accuracy | F1 Macro | ROC-AUC | PR-AUC | Interpretabilidad |
|---------------|----------|----------|---------|--------|------------------|
| GaussianNB    | ~0.80    | ~0.78    | ~0.82   | ~0.75  | Baja (supuestos violados) |
| BernoulliNB   | ~0.79    | ~0.77    | ~0.81   | ~0.74  | Baja |
| SVM Lineal    | ~0.82    | ~0.80    | ~0.84   | ~0.77  | Alta (pesos w) |
| SVM RBF       | ~0.85    | ~0.83    | ~0.87   | ~0.80  | Baja |

---

## ‚úÖ Conclusiones
- **Na√Øve Bayes** es r√°pido y simple, pero sensible a correlaciones entre predictores.  
- **SVM lineal** ofrece interpretabilidad y buen rendimiento.  
- **SVM RBF** logra el mejor desempe√±o global, recomendado si la prioridad es maximizar m√©tricas de clasificaci√≥n.  
- La calibraci√≥n de probabilidades mejora la confiabilidad de las predicciones en ambos enfoques.
